{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from os import path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datadir, expdir, expnum):\n",
    "    '''Creates data frames from a list of files.\n",
    "    \n",
    "    :param datadir\n",
    "        The data directory containing the expriment directories.\n",
    "    :param expdir\n",
    "        A list of expriment directories.\n",
    "    :param expnum\n",
    "        The number of expriment trials per experiment.\n",
    "    :return\n",
    "        A list of data frames.\n",
    "    '''\n",
    "    assert datadir, 'datadir must name a path'\n",
    "    assert expdir, 'expdir cannot be empty'\n",
    "    assert expnum > 0, 'expnum must be greater than zero'\n",
    "    dfs = []\n",
    "    for ed in expdir:\n",
    "        for n in range(1,expnum+1):\n",
    "            filename = '{}-{}.csv'.format(ed, n)\n",
    "            filepath = path.join(datadir, ed, filename)\n",
    "            df = pandas.read_csv(filepath)\n",
    "            dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'data/clean'\n",
    "experiment_dirs = ['exp1', 'exp2', 'exp3']\n",
    "experiment_trials = 5\n",
    "\n",
    "dfs = get_data(datadir, experiment_dirs, experiment_trials)\n",
    "df1 = dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rx', 'ry', 'rz', 'ax', 'ay', 'az', 'mx', 'my', 'mz', 'apprx', 'appry',\n",
      "       'apprz', 'appax', 'appay', 'appaz', 'appmx', 'appmy', 'appmz',\n",
      "       'incontext', 'nocontext'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# The number of columns that will be the input for the neural net model\n",
    "num_cols = len(df1.columns) - 2\n",
    "\n",
    "# Look at the column\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rx</th>\n",
       "      <th>ry</th>\n",
       "      <th>rz</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>mx</th>\n",
       "      <th>my</th>\n",
       "      <th>mz</th>\n",
       "      <th>apprx</th>\n",
       "      <th>appry</th>\n",
       "      <th>apprz</th>\n",
       "      <th>appax</th>\n",
       "      <th>appay</th>\n",
       "      <th>appaz</th>\n",
       "      <th>appmx</th>\n",
       "      <th>appmy</th>\n",
       "      <th>appmz</th>\n",
       "      <th>incontext</th>\n",
       "      <th>nocontext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114776</td>\n",
       "      <td>0.439484</td>\n",
       "      <td>-0.700906</td>\n",
       "      <td>-0.694898</td>\n",
       "      <td>1.077169</td>\n",
       "      <td>1.150464</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>1.636875</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>-1.858940</td>\n",
       "      <td>2.150135</td>\n",
       "      <td>-0.256785</td>\n",
       "      <td>-0.729854</td>\n",
       "      <td>0.786804</td>\n",
       "      <td>-0.229297</td>\n",
       "      <td>-1.041701</td>\n",
       "      <td>0.488485</td>\n",
       "      <td>0.869405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.178055</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>-0.702962</td>\n",
       "      <td>-1.150445</td>\n",
       "      <td>0.410662</td>\n",
       "      <td>0.727458</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>1.636875</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>-1.597529</td>\n",
       "      <td>2.224365</td>\n",
       "      <td>-0.488612</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>1.434085</td>\n",
       "      <td>-0.007593</td>\n",
       "      <td>-1.046289</td>\n",
       "      <td>0.472745</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058157</td>\n",
       "      <td>0.161305</td>\n",
       "      <td>-0.709129</td>\n",
       "      <td>-0.919738</td>\n",
       "      <td>0.436072</td>\n",
       "      <td>1.006316</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-1.446922</td>\n",
       "      <td>1.882911</td>\n",
       "      <td>-0.719377</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>1.362472</td>\n",
       "      <td>-0.043567</td>\n",
       "      <td>-1.019131</td>\n",
       "      <td>0.478037</td>\n",
       "      <td>0.818819</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.607691</td>\n",
       "      <td>-0.657604</td>\n",
       "      <td>-0.657735</td>\n",
       "      <td>-1.256180</td>\n",
       "      <td>1.065773</td>\n",
       "      <td>0.232592</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-1.059426</td>\n",
       "      <td>1.048598</td>\n",
       "      <td>-0.818543</td>\n",
       "      <td>1.110339</td>\n",
       "      <td>0.871966</td>\n",
       "      <td>-0.317667</td>\n",
       "      <td>-0.992060</td>\n",
       "      <td>0.462353</td>\n",
       "      <td>0.760988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.544411</td>\n",
       "      <td>-1.017048</td>\n",
       "      <td>-0.672639</td>\n",
       "      <td>-0.430083</td>\n",
       "      <td>0.144706</td>\n",
       "      <td>-0.634227</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-0.345418</td>\n",
       "      <td>0.132309</td>\n",
       "      <td>-0.549512</td>\n",
       "      <td>0.980732</td>\n",
       "      <td>0.227001</td>\n",
       "      <td>-0.785198</td>\n",
       "      <td>-1.010228</td>\n",
       "      <td>0.446591</td>\n",
       "      <td>0.739677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rx        ry        rz        ax        ay        az        mx  \\\n",
       "0 -0.114776  0.439484 -0.700906 -0.694898  1.077169  1.150464  0.073693   \n",
       "1 -0.178055  0.136300 -0.702962 -1.150445  0.410662  0.727458  0.073693   \n",
       "2 -0.058157  0.161305 -0.709129 -0.919738  0.436072  1.006316  0.001939   \n",
       "3 -0.607691 -0.657604 -0.657735 -1.256180  1.065773  0.232592  0.001939   \n",
       "4 -0.544411 -1.017048 -0.672639 -0.430083  0.144706 -0.634227  0.001939   \n",
       "\n",
       "         my        mz     apprx     appry     apprz     appax     appay  \\\n",
       "0  1.636875  0.559617 -1.858940  2.150135 -0.256785 -0.729854  0.786804   \n",
       "1  1.636875  0.559617 -1.597529  2.224365 -0.488612  0.005991  1.434085   \n",
       "2  1.712917  0.227799 -1.446922  1.882911 -0.719377  0.667759  1.362472   \n",
       "3  1.712917  0.227799 -1.059426  1.048598 -0.818543  1.110339  0.871966   \n",
       "4  1.712917  0.227799 -0.345418  0.132309 -0.549512  0.980732  0.227001   \n",
       "\n",
       "      appaz     appmx     appmy     appmz  incontext  nocontext  \n",
       "0 -0.229297 -1.041701  0.488485  0.869405          1          0  \n",
       "1 -0.007593 -1.046289  0.472745  0.862275          1          0  \n",
       "2 -0.043567 -1.019131  0.478037  0.818819          1          0  \n",
       "3 -0.317667 -0.992060  0.462353  0.760988          1          0  \n",
       "4 -0.785198 -1.010228  0.446591  0.739677          1          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a small sample of the data\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first row of the trial experiment 0\n",
      "[-0.114776  0.439484 -0.700906 -0.694898  1.077169  1.150464  0.073693\n",
      "  1.636875  0.559617 -1.85894   2.150135 -0.256785 -0.729854  0.786804\n",
      " -0.229297 -1.041701  0.488485  0.869405]\n",
      "The target for the trial experiment 0\n",
      "[ 1.  0.]\n",
      "\n",
      "The first row of the trial experiment 5\n",
      "[ 0.247633 -0.314106 -0.22799   0.399076  0.434287 -0.103136  0.182777\n",
      " -2.316515  4.607624  0.090366 -0.229647 -0.274152 -0.118235  0.070525\n",
      "  0.065246 -2.501649 -1.409344  0.614023]\n",
      "The target for the trial experiment 5\n",
      "[ 0.  1.]\n",
      "\n",
      "The first row of the trial experiment 10\n",
      "[ 0.06957  -0.053842 -0.671361 -0.884662 -0.087146  0.641166  0.518448\n",
      " -1.077423  2.031714 -0.244218  0.235017  0.184547 -0.378222  0.101676\n",
      " -0.034164  3.003549 -2.023913 -1.924938]\n",
      "The target for the trial experiment 10\n",
      "[ 0.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_to_input(dfs):\n",
    "    '''Converts a list of data frames to a pair of lists of inputs and targets.\n",
    "    \n",
    "    :param dfs\n",
    "        A list of data frames, where each data frame contains sensor readings from the PowerDue and PowerSense.\n",
    "    :return\n",
    "        A pair of lists (inputs, targets), where\n",
    "        - each input in inputs is an array of the sensor readings for one experiment.\n",
    "        - each target in targets is a vector of length two, where\n",
    "          - [1, 0] represents a target where the PowerDue and mobile phone share context.\n",
    "          - [0, 1] represents a target where the PowerDue and mobile phone do not share context.\n",
    "    '''\n",
    "    assert dfs, 'dfs cannot be empty'\n",
    "    values = []\n",
    "    targets = []\n",
    "    cols = dfs[0].columns\n",
    "    value_cols = cols[:-2]\n",
    "    target_cols = cols[-2:]\n",
    "    for df in dfs:\n",
    "        value = df[value_cols].values\n",
    "        target = df.iloc[0][target_cols].values\n",
    "        values.append(value)\n",
    "        targets.append(target)\n",
    "    return values, targets     \n",
    "\n",
    "inputs, targets = convert_to_input(dfs)\n",
    "for i in range(0, len(inputs), 5):\n",
    "    value, target = inputs[i], targets[i]\n",
    "    print('The first row of the trial experiment %d' % i)\n",
    "    print(value[0, :])\n",
    "    print('The target for the trial experiment %d' %i)\n",
    "    print(target)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays have 2431 rows\n"
     ]
    }
   ],
   "source": [
    "def normalize_rows(data):\n",
    "    '''Normalizes the rows in data by making them have the same number of rows.\n",
    "    \n",
    "    The number of rows that for each array will be the average number of rows.\n",
    "    If an array has less rows then needed, then the last row is repeated until\n",
    "    the array has the correct number of rows. If the array has more rows than\n",
    "    needed, then the last rows are dropped.\n",
    "    \n",
    "    :param data\n",
    "        A list of arrays\n",
    "    :return\n",
    "        A list of arrays with the same number of rows.\n",
    "    '''\n",
    "    assert len(data) != 0, 'cannot divide by zero'\n",
    "    rows_mean = int(sum(arr.shape[0] for arr in data) / len(data))\n",
    "    new_data = []\n",
    "    for arr in data:\n",
    "        rows = arr.shape[0]\n",
    "        if rows > rows_mean:\n",
    "            new_data.append(arr[:rows_mean, :])\n",
    "        elif rows < rows_mean:\n",
    "            diff_rows = rows_mean - rows\n",
    "            # Repeat the last row\n",
    "            arr_repeat = numpy.tile(arr[-1,:], (diff_rows, 1))\n",
    "            new_arr = numpy.append(arr, arr_repeat, axis=0)\n",
    "            new_data.append(new_arr)\n",
    "        else:\n",
    "            new_data.append(arr)\n",
    "    return new_data\n",
    "\n",
    "# Verify that all arrays have same number of rows\n",
    "norm_rows_data = normalize_rows(inputs)\n",
    "rows_num = norm_rows_data[0].shape[0]\n",
    "assert all(rows_num == arr.shape[0] for arr in norm_rows_data), \\\n",
    "    'not all arrays have the same number of rows'\n",
    "print('All arrays have {} rows'.format(rows_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xform_data.shape: (15, 2431, 18, 1)\n",
      "input_shape: (2431, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "def reshape_data(data):\n",
    "    '''Reshapes 2d arrays into 3d arrays.\n",
    "    \n",
    "    :param data\n",
    "        A list of 2d numpy arrays\n",
    "    :return\n",
    "        A list of 3d numpy arrays and a tuple of input parameters that can be fed to a Keras layer.\n",
    "    '''\n",
    "    new_data = numpy.array(data)\n",
    "    samples, rows, cols = new_data.shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        new_data = new_data.reshape(samples, 1, rows, cols)\n",
    "        input_shape = (1, rows, cols)\n",
    "    else:\n",
    "        new_data = new_data.reshape(samples, rows, cols, 1)\n",
    "        input_shape = (rows, cols, 1) \n",
    "    return input_shape, new_data\n",
    "\n",
    "input_shape, xform_data = reshape_data(norm_rows_data)\n",
    "print('xform_data.shape:', xform_data.shape)\n",
    "print('input_shape:', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    '''Creates an uncompiled neural net model.\n",
    "    \n",
    "    :return\n",
    "        An uncompiled neural net model.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_targets = numpy.array(targets)\n",
    "arr_inputs = xform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [0.029746450483798981, 1.0]\n",
      "acc: 100.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Compile the neural net\n",
    "nsamples = arr_inputs.shape[0]\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "zeros = numpy.zeros(nsamples)\n",
    "# Leave one out k-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=nsamples, shuffle=True, random_state=seed)\n",
    "scores = []\n",
    "for train, test in kfold.split(zeros, zeros):\n",
    "    model = create_model(input_shape)\n",
    "    # Compile model\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    train_inputs = arr_inputs[train]\n",
    "    train_targets = arr_targets[train]\n",
    "    model.fit(train_inputs, train_targets, epochs=20, batch_size=10, verbose=0)\n",
    "    test_input = arr_inputs[test]\n",
    "    test_target = arr_targets[test]\n",
    "    score_tuple = model.evaluate(test_input, test_target, verbose=0)\n",
    "    score = int(score_tuple[1])\n",
    "    print('score=', score_tuple, 'GUESSED RIGHT!!!' if score else 'WRONG!!!')\n",
    "    scores.append((test[0], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (7, 0), (8, 0), (9, 0), (10, 0), (11, 0), (12, 0), (13, 0), (14, 0)]\n",
      "Guessed 0/15 correct\n"
     ]
    }
   ],
   "source": [
    "# See which experiment trials are predicted correctly (i.e., second element is 1)\n",
    "scores.sort()\n",
    "print('Scores:', scores)\n",
    "correct = sum(guess for _, guess in scores)\n",
    "print('Guessed {}/{} correct'.format(correct, len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather results to plot predictions against actual data\n",
    "\n",
    "x = list(range(1,len(scores)+1))\n",
    "\n",
    "y_hat, y = [], []\n",
    "for i, s in scores:\n",
    "    if i < 5:\n",
    "        actual = 1\n",
    "        guess = 1 if s else 0\n",
    "    else:\n",
    "        guess = 0 if s else 1\n",
    "        actual = 0\n",
    "    y_hat.append(guess)\n",
    "    y.append(actual)\n",
    "    \n",
    "y = x\n",
    "y_hat = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7NScoIyM7NS+v9vb//XBN2LkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9163be6240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y_hat, 'ko')\n",
    "plt.title('Predictions')\n",
    "plt.ylabel('Experiment#')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.title('Observ')\n",
    "plt.xlabel('Experiment#')\n",
    "plt.ylabel('Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
