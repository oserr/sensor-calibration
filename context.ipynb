{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from os import path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datadir, expdir, expnum):\n",
    "    '''Creates data frames from a list of files.\n",
    "    \n",
    "    :param datadir\n",
    "        The data directory containing the expriment directories.\n",
    "    :param expdir\n",
    "        A list of expriment directories.\n",
    "    :param expnum\n",
    "        The number of expriment trials per experiment.\n",
    "    :return\n",
    "        A list of data frames.\n",
    "    '''\n",
    "    assert datadir, 'datadir must name a path'\n",
    "    assert expdir, 'expdir cannot be empty'\n",
    "    assert expnum > 0, 'expnum must be greater than zero'\n",
    "    dfs = []\n",
    "    for ed in expdir:\n",
    "        for n in range(1,expnum+1):\n",
    "            filename = '{}-{}.csv'.format(ed, n)\n",
    "            filepath = path.join(datadir, ed, filename)\n",
    "            df = pandas.read_csv(filepath)\n",
    "            dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'data/clean'\n",
    "experiment_dirs = ['exp1', 'exp2', 'exp3']\n",
    "experiment_trials = 5\n",
    "\n",
    "dfs = get_data(datadir, experiment_dirs, experiment_trials)\n",
    "df1 = dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rx', 'ry', 'rz', 'ax', 'ay', 'az', 'mx', 'my', 'mz', 'apprx', 'appry',\n",
      "       'apprz', 'appax', 'appay', 'appaz', 'appmx', 'appmy', 'appmz',\n",
      "       'incontext', 'nocontext'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# The number of columns that will be the input for the neural net model\n",
    "num_cols = len(df1.columns) - 2\n",
    "\n",
    "# Look at the column\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rx</th>\n",
       "      <th>ry</th>\n",
       "      <th>rz</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>mx</th>\n",
       "      <th>my</th>\n",
       "      <th>mz</th>\n",
       "      <th>apprx</th>\n",
       "      <th>appry</th>\n",
       "      <th>apprz</th>\n",
       "      <th>appax</th>\n",
       "      <th>appay</th>\n",
       "      <th>appaz</th>\n",
       "      <th>appmx</th>\n",
       "      <th>appmy</th>\n",
       "      <th>appmz</th>\n",
       "      <th>incontext</th>\n",
       "      <th>nocontext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114776</td>\n",
       "      <td>0.439484</td>\n",
       "      <td>-0.700906</td>\n",
       "      <td>-0.694898</td>\n",
       "      <td>1.077169</td>\n",
       "      <td>1.150464</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>1.636875</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>-1.858940</td>\n",
       "      <td>2.150135</td>\n",
       "      <td>-0.256785</td>\n",
       "      <td>-0.729854</td>\n",
       "      <td>0.786804</td>\n",
       "      <td>-0.229297</td>\n",
       "      <td>-1.041701</td>\n",
       "      <td>0.488485</td>\n",
       "      <td>0.869405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.178055</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>-0.702962</td>\n",
       "      <td>-1.150445</td>\n",
       "      <td>0.410662</td>\n",
       "      <td>0.727458</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>1.636875</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>-1.597529</td>\n",
       "      <td>2.224365</td>\n",
       "      <td>-0.488612</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>1.434085</td>\n",
       "      <td>-0.007593</td>\n",
       "      <td>-1.046289</td>\n",
       "      <td>0.472745</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058157</td>\n",
       "      <td>0.161305</td>\n",
       "      <td>-0.709129</td>\n",
       "      <td>-0.919738</td>\n",
       "      <td>0.436072</td>\n",
       "      <td>1.006316</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-1.446922</td>\n",
       "      <td>1.882911</td>\n",
       "      <td>-0.719377</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>1.362472</td>\n",
       "      <td>-0.043567</td>\n",
       "      <td>-1.019131</td>\n",
       "      <td>0.478037</td>\n",
       "      <td>0.818819</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.607691</td>\n",
       "      <td>-0.657604</td>\n",
       "      <td>-0.657735</td>\n",
       "      <td>-1.256180</td>\n",
       "      <td>1.065773</td>\n",
       "      <td>0.232592</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-1.059426</td>\n",
       "      <td>1.048598</td>\n",
       "      <td>-0.818543</td>\n",
       "      <td>1.110339</td>\n",
       "      <td>0.871966</td>\n",
       "      <td>-0.317667</td>\n",
       "      <td>-0.992060</td>\n",
       "      <td>0.462353</td>\n",
       "      <td>0.760988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.544411</td>\n",
       "      <td>-1.017048</td>\n",
       "      <td>-0.672639</td>\n",
       "      <td>-0.430083</td>\n",
       "      <td>0.144706</td>\n",
       "      <td>-0.634227</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-0.345418</td>\n",
       "      <td>0.132309</td>\n",
       "      <td>-0.549512</td>\n",
       "      <td>0.980732</td>\n",
       "      <td>0.227001</td>\n",
       "      <td>-0.785198</td>\n",
       "      <td>-1.010228</td>\n",
       "      <td>0.446591</td>\n",
       "      <td>0.739677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rx        ry        rz        ax        ay        az        mx  \\\n",
       "0 -0.114776  0.439484 -0.700906 -0.694898  1.077169  1.150464  0.073693   \n",
       "1 -0.178055  0.136300 -0.702962 -1.150445  0.410662  0.727458  0.073693   \n",
       "2 -0.058157  0.161305 -0.709129 -0.919738  0.436072  1.006316  0.001939   \n",
       "3 -0.607691 -0.657604 -0.657735 -1.256180  1.065773  0.232592  0.001939   \n",
       "4 -0.544411 -1.017048 -0.672639 -0.430083  0.144706 -0.634227  0.001939   \n",
       "\n",
       "         my        mz     apprx     appry     apprz     appax     appay  \\\n",
       "0  1.636875  0.559617 -1.858940  2.150135 -0.256785 -0.729854  0.786804   \n",
       "1  1.636875  0.559617 -1.597529  2.224365 -0.488612  0.005991  1.434085   \n",
       "2  1.712917  0.227799 -1.446922  1.882911 -0.719377  0.667759  1.362472   \n",
       "3  1.712917  0.227799 -1.059426  1.048598 -0.818543  1.110339  0.871966   \n",
       "4  1.712917  0.227799 -0.345418  0.132309 -0.549512  0.980732  0.227001   \n",
       "\n",
       "      appaz     appmx     appmy     appmz  incontext  nocontext  \n",
       "0 -0.229297 -1.041701  0.488485  0.869405          1          0  \n",
       "1 -0.007593 -1.046289  0.472745  0.862275          1          0  \n",
       "2 -0.043567 -1.019131  0.478037  0.818819          1          0  \n",
       "3 -0.317667 -0.992060  0.462353  0.760988          1          0  \n",
       "4 -0.785198 -1.010228  0.446591  0.739677          1          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a small sample of the data\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first row of the trial experiment 0\n",
      "[-0.114776  0.439484 -0.700906 -0.694898  1.077169  1.150464  0.073693\n",
      "  1.636875  0.559617 -1.85894   2.150135 -0.256785 -0.729854  0.786804\n",
      " -0.229297 -1.041701  0.488485  0.869405]\n",
      "The target for the trial experiment 0\n",
      "[ 1.  0.]\n",
      "\n",
      "The first row of the trial experiment 5\n",
      "[ 0.247633 -0.314106 -0.22799   0.399076  0.434287 -0.103136  0.182777\n",
      " -2.316515  4.607624  0.090366 -0.229647 -0.274152 -0.118235  0.070525\n",
      "  0.065246 -2.501649 -1.409344  0.614023]\n",
      "The target for the trial experiment 5\n",
      "[ 0.  1.]\n",
      "\n",
      "The first row of the trial experiment 10\n",
      "[ 0.06957  -0.053842 -0.671361 -0.884662 -0.087146  0.641166  0.518448\n",
      " -1.077423  2.031714 -0.244218  0.235017  0.184547 -0.378222  0.101676\n",
      " -0.034164  3.003549 -2.023913 -1.924938]\n",
      "The target for the trial experiment 10\n",
      "[ 0.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_to_input(dfs):\n",
    "    '''Converts a list of data frames to a pair of lists of inputs and targets.\n",
    "    \n",
    "    :param dfs\n",
    "        A list of data frames, where each data frame contains sensor readings from the PowerDue and PowerSense.\n",
    "    :return\n",
    "        A pair of lists (inputs, targets), where\n",
    "        - each input in inputs is an array of the sensor readings for one experiment.\n",
    "        - each target in targets is a vector of length two, where\n",
    "          - [1, 0] represents a target where the PowerDue and mobile phone share context.\n",
    "          - [0, 1] represents a target where the PowerDue and mobile phone do not share context.\n",
    "    '''\n",
    "    assert dfs, 'dfs cannot be empty'\n",
    "    values = []\n",
    "    targets = []\n",
    "    cols = dfs[0].columns\n",
    "    value_cols = cols[:-2]\n",
    "    target_cols = cols[-2:]\n",
    "    for df in dfs:\n",
    "        value = df[value_cols].values\n",
    "        target = df.iloc[0][target_cols].values\n",
    "        values.append(value)\n",
    "        targets.append(target)\n",
    "    return values, targets     \n",
    "\n",
    "inputs, targets = convert_to_input(dfs)\n",
    "for i in range(0, len(inputs), 5):\n",
    "    value, target = inputs[i], targets[i]\n",
    "    print('The first row of the trial experiment %d' % i)\n",
    "    print(value[0, :])\n",
    "    print('The target for the trial experiment %d' %i)\n",
    "    print(target)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays have 2431 rows\n"
     ]
    }
   ],
   "source": [
    "def normalize_rows(data):\n",
    "    '''Normalizes the rows in data by making them have the same number of rows.\n",
    "    \n",
    "    The number of rows that for each array will be the average number of rows.\n",
    "    If an array has less rows then needed, then the last row is repeated until\n",
    "    the array has the correct number of rows. If the array has more rows than\n",
    "    needed, then the last rows are dropped.\n",
    "    \n",
    "    :param data\n",
    "        A list of arrays\n",
    "    :return\n",
    "        A list of arrays with the same number of rows.\n",
    "    '''\n",
    "    assert len(data) != 0, 'cannot divide by zero'\n",
    "    rows_mean = int(sum(arr.shape[0] for arr in data) / len(data))\n",
    "    new_data = []\n",
    "    for arr in data:\n",
    "        rows = arr.shape[0]\n",
    "        if rows > rows_mean:\n",
    "            new_data.append(arr[:rows_mean, :])\n",
    "        elif rows < rows_mean:\n",
    "            diff_rows = rows_mean - rows\n",
    "            # Repeat the last row\n",
    "            arr_repeat = numpy.tile(arr[-1,:], (diff_rows, 1))\n",
    "            new_arr = numpy.append(arr, arr_repeat, axis=0)\n",
    "            new_data.append(new_arr)\n",
    "        else:\n",
    "            new_data.append(arr)\n",
    "    return new_data\n",
    "\n",
    "# Verify that all arrays have same number of rows\n",
    "norm_rows_data = normalize_rows(inputs)\n",
    "rows_num = norm_rows_data[0].shape[0]\n",
    "assert all(rows_num == arr.shape[0] for arr in norm_rows_data), \\\n",
    "    'not all arrays have the same number of rows'\n",
    "print('All arrays have {} rows'.format(rows_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xform_data.shape: (15, 2431, 18, 1)\n",
      "input_shape: (2431, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "def reshape_data(data):\n",
    "    '''Reshapes 2d arrays into 3d arrays.\n",
    "    \n",
    "    :param data\n",
    "        A list of 2d numpy arrays\n",
    "    :return\n",
    "        A list of 3d numpy arrays and a tuple of input parameters that can be fed to a Keras layer.\n",
    "    '''\n",
    "    new_data = numpy.array(data)\n",
    "    samples, rows, cols = new_data.shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        new_data = new_data.reshape(samples, 1, rows, cols)\n",
    "        input_shape = (1, rows, cols)\n",
    "    else:\n",
    "        new_data = new_data.reshape(samples, rows, cols, 1)\n",
    "        input_shape = (rows, cols, 1) \n",
    "    return input_shape, new_data\n",
    "\n",
    "input_shape, xform_data = reshape_data(norm_rows_data)\n",
    "print('xform_data.shape:', xform_data.shape)\n",
    "print('input_shape:', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    '''Creates an uncompiled neural net model.\n",
    "    \n",
    "    :return\n",
    "        An uncompiled neural net model.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_targets = numpy.array(targets)\n",
    "arr_inputs = xform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score= [1.1920930376163597e-07, 1.0] GUESSED RIGHT!!!\n",
      "score= [1.1920930376163597e-07, 1.0] GUESSED RIGHT!!!\n",
      "score= [1.1920930376163597e-07, 1.0] GUESSED RIGHT!!!\n",
      "score= [16.118095397949219, 0.0] WRONG!!!\n",
      "score= [0.005261649377644062, 1.0] GUESSED RIGHT!!!\n",
      "score= [16.118095397949219, 0.0] WRONG!!!\n",
      "score= [16.118095397949219, 0.0] WRONG!!!\n",
      "score= [1.1920930376163597e-07, 1.0] GUESSED RIGHT!!!\n",
      "score= [1.1920930376163597e-07, 1.0] GUESSED RIGHT!!!\n",
      "score= [16.118095397949219, 0.0] WRONG!!!\n",
      "score= [16.118095397949219, 0.0] WRONG!!!\n",
      "score= [16.118095397949219, 0.0] WRONG!!!\n",
      "score= [1.1920930376163597e-07, 1.0] GUESSED RIGHT!!!\n",
      "score= [1.1920930376163597e-07, 1.0] GUESSED RIGHT!!!\n",
      "score= [16.118095397949219, 0.0] WRONG!!!\n"
     ]
    }
   ],
   "source": [
    "# Compile the neural net\n",
    "nsamples = arr_inputs.shape[0]\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "zeros = numpy.zeros(nsamples)\n",
    "# Leave one out k-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=nsamples, shuffle=True, random_state=seed)\n",
    "scores = []\n",
    "for train, test in kfold.split(zeros, zeros):\n",
    "    model = create_model(input_shape)\n",
    "    # Compile model\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    train_inputs = arr_inputs[train]\n",
    "    train_targets = arr_targets[train]\n",
    "    model.fit(train_inputs, train_targets, epochs=20, batch_size=10, verbose=0)\n",
    "    test_input = arr_inputs[test]\n",
    "    test_target = arr_targets[test]\n",
    "    score_tuple = model.evaluate(test_input, test_target, verbose=0)\n",
    "    score = int(score_tuple[1])\n",
    "    print('score=', score_tuple, 'GUESSED RIGHT!!!' if score else 'WRONG!!!')\n",
    "    scores.append((test[0], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 1), (6, 1), (7, 0), (8, 1), (9, 1), (10, 1), (11, 0), (12, 1), (13, 1), (14, 1)]\n",
      "Guessed 8/15 correct\n"
     ]
    }
   ],
   "source": [
    "# See which experiment trials are predicted correctly (i.e., second element is 1)\n",
    "scores.sort()\n",
    "print('Scores:', scores)\n",
    "correct = sum(guess for _, guess in scores)\n",
    "print('Guessed {}/{} correct'.format(correct, len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather results to plot predictions against actual data\n",
    "\n",
    "x = list(range(1,len(scores)+1))\n",
    "\n",
    "y_hat, y = [], []\n",
    "for i, s in scores:\n",
    "    if i < 5:\n",
    "        actual = 1\n",
    "        guess = 1 if s else 0\n",
    "    else:\n",
    "        guess = 0 if s else 1\n",
    "        actual = 0\n",
    "    y_hat.append(guess)\n",
    "    y.append(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHcNJREFUeJzt3XuYHHWd7/H3J5MEEkRFM15IyAyw\n8QjqojKKiIvjriDgEdCzKFGP4KNGF5FddHdFjwcRF3XZ9bIqXlhFOE4EcfWwQVH04WxEDSiTI4KA\nORtjbnIb5CYgYML3/FG/gUqnZ6Ym6Zr+dffn9Tz1dFfVr3/1rZn69rfr0tWKCMzMzHIzq90BmJmZ\nNeMCZWZmWXKBMjOzLLlAmZlZllygzMwsSy5QZmaWJRco2ymSzpA0kp4vlnSfpL4d6Of9kr7U+gjN\npk/SsKTN7Y6j17lATUDS6yWNpjfcWyR9V9JLWtDv+ZL+oUUxnijpx63oqxUiYmNEPC4itk7Wrlny\nR8RHIuKt9UZonULSSkl3SdqlYvtBSSFpdt2x1aWb3xt2lAtUE5LeDXwK+AjwVGAx8DngmHbGVbdO\nTm7rHpIGgT8DAji6rcFYe0WEh9IAPAG4Dzhukja7UBSwm9PwKWCXNG8Y2Ay8B7gduAV4c5q3DPgj\n8HBaxqVp+p7AN4Ex4DfAKaVlXQZ8vDT+deA8YD/gQWBr6uvuCWJdCXwU+BlwD/DvwJPSvEGKN4G3\nABuBK9P0FwGrgLuBXwDDpf72Bn4I/B74AfBZYKShv9lp/EnAV9Lf6C7gEmA34A/AIynu+9L6nzHe\nT3rt0cANKYaVwH6leeuBvwWuS+v0dWDXdm87HlqWg6cDPwE+AXy7Yd484OPAhvS//3GatjFte+Pb\n1MFNtqnG7fPNwE1pW14HvL3UdhjYPEmMz0rb/53AbcD70/SOeW/ohKHtAeQ2AEcAW8Y34gnanAlc\nDTwF6Kd4M/9waSPcktrMAY4CHgD2SPPPB/6h1NcsYHVKyrnAPilZXpHmPy1tzH8OvCHN2z3NOxH4\n8RTrsxL4LfBsiuLwTbYvKP8rzZsHLAR+l+KeBRyWxvvTa66ieOPYBTg0JfdEBeo7KWn2SH+Ll5b+\nRpsb4jyj1M8zgPvTsucAfw+sBeam+espCu6eFEXwJuAd7d52PLQsB9cCJwEHUrxpP7U075y0TS8E\n+oAXp21xm22vcZuaYPt8JbAvIOClKU+fP9E2Wupnd4ri8h5g1zR+UJrXMe8NnTC0PYDchvSPvnWK\nNr8GjiqNvwJYn54PU+whlBPlduBF6XnjRngQsLGh//cBXymNvwbYBNwBvKQ0fcqNMCXzx0rj+1N8\nSusrJew+pfnvBb7a0MflwAkUhzq3ALuV5n2NJgUKeDrFXtIeTWLaLvnZtkD9T+Di0rxZFEV2OI2v\nB95Ymn828IV2bzsedn4AXkJRlBak8V8Bp5a2gz8ABzR53aPbXrNtaqI2DX1cAvx1er7dNlpqtxT4\n+QTzOua9oRMGn4Pa3u+ABVOcj9mT4hDDuA1p2qN9RMSW0vgDwOMm6GsA2FPS3eMD8H6Kc1/jvk1R\nUNZExI6c+NzUEOscYMEE8weA4xrieQlFwdkTuCsi7m/or5m9gDsj4q4diHebv29EPJJiXFhqc2vp\n+WR/X+ssJwDfj4g70vjX0jQottldKYrATpN0pKSrJd2ZtvOj2DYvJrLXJDF02ntD1lygtncVxfHb\nYydpczPFxjNucZpWRePt4zcBv4mIJ5aG3SPiqFKbsygOYz1d0tJJ+prIXg2x/pHiE1ezfjZR7EGV\n49ktIj5GcVhjD0m7NfTXzCbgSZKe2GTeVHFv8/eVpLQOv53iddbBJM0DXgu8VNKtkm4FTgUOkHQA\nxTb7IMVhuUbNtqn7gfml8aeVlrULxeHuf6Y4hPhEinM6qhDqpgligM57b8iaC1SDiLiH4pjvOZKO\nlTRf0pz0aevs1OxC4AOS+iUtSO1HKi7iNopjyeN+Btwr6b2S5knqk/RsSS8AkHQoxcncN6XhM5IW\nlvpaJGnuFMt8o6T9Jc2nOP79bzHxpeAjwKskvSLFsmu6LHxRRGwARoEPSZqbLrt/VbNOIuIW4LvA\n5yTtkf6Gh5bifrKkJ0wQw8XAKyX9haQ5FMf6H6I4nm/d61iKE/v7A89Nw37Aj4A3pT3p84BPSNoz\nbZ8Hp2IzRnFIuZxb1wKHpu/nPYHi8Ni4uRTnrsaALZKOBA6vGOe3gadJ+htJu0jaXdJBaV6nvTfk\nrd3HGHMdKM5FjVJ8CruV4oT/i9O8XYFPU+xR3JKe75rmDbP9+ZX1wMvT8yUUiXM3cEmatifFhn0r\nxdVuVwMvBx6fXnt8qa9/BL5P8UlvborrTuCOCdZjJY9dxXcvcCmPHd8fpMkxeYpj3z9M/Y6lZSxO\n8/aheMO4j2pX8V1AkSx3Ad8qLeM8isOpd9P8Kr5XAzdSXKn1Q+BZzf6eaXyb13rozAH4HqWr0krT\nX5tyYzbFhTyfotibvge4EpiX2p2Ztte7eey8zjlpfC3wtobt851p27wb+CpwEekcULM8bojp2cAV\nabu+FTgtTe+Y94ZOGJRWzLqUpJUUb96+S4OZdRQf4jMzsyy5QJmZWZZ8iM/MzLLkPSgzM8tSx90c\ndMGCBTE4ONjuMKxHrV69+o6I6G93HK3gXLJ2qZpHHVegBgcHGR0dbXcY1qMkTXTnjI7jXLJ2qZpH\nPsRnZmZZcoEyM7MsuUCZmVmWXKDMzCxLLlBmZpal2gqUpPMk3S7plxPMl6RPS1or6TpJz68rFoPl\ny5czODjIrFmzGBwcZPny5e0OaTudEGM7OJesV9W5B3U+xc+nT+RIirv3LgGWAZ+vMZaetnz5cpYt\nW8aGDRuICDZs2MCyZcuyKgCdEGMbnc9M5tJVV8FHP1o8tqJdHX1OZ9nWuWq+ff4g8MsJ5n0RWFoa\nXwM8fao+DzzwwLDpGRgYCIqfGdhmGBgYaHdoj+qEGCMigNFow88OzFgurVoVMW9eRF9f8bhqVfM/\nRNV2dfQ5nWVblqrmUTvPQS1k258a38y2P+n9KEnLJI1KGh0bG5uR4LrJxo0bpzW9HTohxoy1LpdW\nroSHH4atW4vHlSubL7Fquzr6nM6yraO1s0A1+2nlpneujYhzI2IoIob6+7viLjMzavHi5r/KPtH0\nduiEGDPWulwaHoa5c6Gvr3gcHm6+xKrt6uhzOsu2jtbOWx1tBvYqjS8Cbm5TLF3trLPOYtmyZTzw\nwAOPTps/fz5nnXVWG6PaVifEmLHW5dLBB8MVVxR7JcPDxfjOtKujz+ks2zpbleOAOzow+XHzVwLf\npfj09yLgZ1X69DmoHTMyMhIDAwMhKQYGBmJkZKTdIW2nE2Ikz3NQziXrKFXzqLbfg5J0ITAMLABu\nAz4IzElF8QuSBHyW4uqkB4A3R8SUd64cGhoK3+DS2kXS6ogYmuFlOpesq1TNo9oO8UXE0inmB/DO\nupZv1i2cS9arfCcJMzPLkguUmZllyQXKzMyy5AJlZmZZcoEyM7MsuUCZmVmWXKDMzCxLLlBmZpYl\nFygzM8uSC5SZmWXJBcrMzLLkAmVmZllygTIzsyy5QJmZWZZcoMzMLEsuUGZmliUXKDMzy5ILlJmZ\nZckFyszMsuQCZWZmWXKBMjOzLLlAmZlZllygzMwsSy5QZmaWJRcoMzPLkguUmZllyQXKzMyy5AJl\nZmZZcoEyM7MsuUCZmVmWXKDMzCxLtRYoSUdIWiNpraTTmsxfLOk/JP1c0nWSjqozHrNO5VyyXlRb\ngZLUB5wDHAnsDyyVtH9Dsw8AF0fE84Djgc/VFY9Zp3IuWa+qcw/qhcDaiFgXEQ8DFwHHNLQJ4PHp\n+ROAm2uMx6xTOZesJ9VZoBYCm0rjm9O0sjOAN0raDFwGvKtZR5KWSRqVNDo2NlZHrGY5cy5ZT6qz\nQKnJtGgYXwqcHxGLgKOAr0raLqaIODcihiJiqL+/v4ZQzbLmXLKeVGeB2gzsVRpfxPaHHd4CXAwQ\nEVcBuwILaozJrBM5l6wn1VmgrgGWSNpb0lyKE7crGtpsBP4CQNJ+FEnl4w5m23IuWU+qrUBFxBbg\nZOBy4CaKK4xukHSmpKNTs/cAb5P0C+BC4MSIaDx0YdbTnEvWq2bX2XlEXEZxwrY87fTS8xuBQ+qM\nwawbOJesF/lOEmZmliUXKDMzy5ILlJmZZckFyszMsuQCZWZmWXKBMjOzLLlAmZlZllygzMwsSy5Q\nZmaWJRcoMzPLkguUmZllyQXKzMyy5AJlZmZZcoEyM7MsuUCZmVmWXKDMzCxLLlBmZpYlFygzM8uS\nC5SZmWXJBcrMzLLkAmVmZllygTIzsyy5QJmZWZZcoMzMLEsuUGZmliUXKDMzy5ILlJmZZckFyszM\nsuQCZWZmWXKBMjOzLLlAmZlZlmotUJKOkLRG0lpJp03Q5rWSbpR0g6Sv1RmPWSdyHlmvml21oaSF\nwED5NRFx5STt+4BzgMOAzcA1klZExI2lNkuA9wGHRMRdkp4y/VUw617OI+tllQqUpH8EXgfcCGxN\nkwOYsEABLwTWRsS61MdFwDGpj3FvA86JiLsAIuL2aUVv1v2cR9azqu5BHQv8l4h4aBp9LwQ2lcY3\nAwc1tHkGgKSfAH3AGRHxvcaOJC0DlgEsXrx4GiGYdbyW5VFq41yyjlH1HNQ6YM40+1aTadEwPhtY\nAgwDS4EvSXridi+KODcihiJiqL+/f5phmHW0luUROJess1Tdg3oAuFbSFcCje1ERccokr9kM7FUa\nXwTc3KTN1RHxR+A3ktZQJNo1FeMy63bOI+tZVfegVgAfBlYBq0vDZK4BlkjaW9Jc4PjUT9klwMsA\nJC2gOFSxrmJMZr3AeWQ9q9IeVERckJLjGWnSmvRpbbLXbJF0MnA5xXHx8yLiBklnAqMRsSLNO1zS\n+MUXfxcRv9vRlTHrNs4j62WKaDyc3aSRNAxcAKynOCa+F3DCZJeZ12VoaChGR0dnerFmAEhaHRFD\n7Y6jFZxL1i5V86jqOaiPA4dHxJrU+TOAC4EDdzxEMzOziVU9BzVnvDgBRMT/Y/pX9ZmZmVVWdQ9q\nVNKXga+m8Tcw9UUSZmZmO6xqgfor4J3AKRTnoK4EPldXUGZmZlWv4nsI+EQazMzMajdpgZJ0cUS8\nVtL1bP/tdSLiT2uLzMzMetpUe1B/nR7/a92BmPUCSS8CPgPsB8yl+G7T/RHx+LYGZpahSa/ii4hb\n0tOTImJDeQBOqj88s67zWYr75f0nMA94K0XBMrMGVS8zP6zJtCNbGYhZr4iItUBfRGyNiK+QblNk\nZtua6hzUX1HsKe0r6brSrN0p7stnZtPzQLpt2LWSzgZuAXZrc0xmWZrqHNTXgO8CHwXKPzX9+4i4\ns7aozLrXf6c4cnEycCrFbcNe09aIzDI11TmoeyJiPfAvwJ2l809/lNT4o2lmNrVjI+LBiLg3Ij4U\nEe/GFyGZNVX1HNTngftK4/enaWY2PSc0mXbiTAdh1gmq3klCUbrteUQ8Iqnqa816nqSlwOuBvSWV\nf89pd8A/jWHWRNUis07SKTy213QS/kE0s+lYRXFBxAKKXwcY93vguqavMOtxVQvUO4BPAx+guKPE\nFcCyuoIy6zbp3O0G4OB2x2LWKarei+92ip+aNrOd4DtJmFU31feg/j4izpb0GZrfi++U2iIz606f\npfiw9w1gCHgT8CdtjcgsU1PtQd2UHv270GYtEhFrJfVFxFbgK5L8pXezJiYtUBFxaXq8YGbCMet6\nvpOEWUVTHeK7lCaH9sZFxNEtj8isuzW7k8R/a2tEZpma6hDfP6fH1wBPA0bS+FJgfU0xmXWtiNgg\nqT89/1C74zHL2VSH+H4IIOnDEXFoadalkq6sNTKzLiJJwAcp9pwEzJK0BfhMRJzZ1uDMMlX1Vkf9\nkvYZH5G0N9BfT0hmXelvgEOAF0TEkyNiD+Ag4BBJp7Y3NLM8Vf2i7qnASknjd48YBN5eS0Rm3elN\nwGERccf4hIhYJ+mNwPeBT7YtMrNMVf2i7vckLQGemSb9KiIeqi8ss64zp1ycxkXEmKQ57QjILHeV\nDvFJmg/8HXByRPwCWCzJPxFgVt3DOzjPrGdVPcT3FWA1j91HbDPFN+G/XUdQZl3oAEn3NpkuYNeZ\nDsasE1QtUPtGxOvSTwYQEX9IVyWZWQUR0dfuGMw6TdWr+B6WNI/0pV1J+wI+B2VmZrWpugf1QeB7\nwF6SllNcLntiXUGZmZlNuQeVDuX9iuJuEicCFwJDEbGywmuPkLRG0lpJp03S7i8lhaShypGb9RDn\nkvWiKfegIiIkXRIRBwLfqdqxpD7gHOAwiosqrpG0IiJubGi3O3AK8NNpRW7WI5xL1quqnoO6WtIL\nptn3C4G1EbEuIh4GLgKOadLuw8DZwIPT7N+sVziXrCdVLVAvoyhSv5Z0naTrJV03xWsWAptK45vT\ntEdJeh6wV0RMerm6pGWSRiWNjo2NVQzZrGs4l6wnVb1I4sgd6LvZZeiP/nSHpFkUt3c5caqOIuJc\n4FyAoaGhCX/+w6xLOZesJ031e1C7Au+g+Enq64EvR8SWin1vpvitm3GLgJtL47sDz6a4xx8UP+ex\nQtLREeFf8DV7jHPJetJUh/guAIYoitORwMen0fc1wBJJe6dfED0eWDE+MyLuiYgFETEYEYPA1YAT\nymx7ziXrSVMd4ts/Ip4DIOnLwM+qdhwRWySdDFwO9AHnRcQNks4ERiNixeQ9mBk4l6x3TVWg/jj+\nJCXJtDqPiMuAyxqmnT5B2+FpdW7WQ5xL1oumKlDlG1wKmJfGRfEVqcfXGp2ZmfWsqX7y3Te4NDOz\ntqj6PSgzM7MZ5QJlZmZZcoEyM7MsuUCZmVmWXKDMzCxLLlBmZpYlFygzM8uSC5SZmWXJBcrMzLLk\nAmVmZllygTIzsyy5QJmZWZZcoMzMLEsuUGZmliUXKDMzy5ILlJmZZckFyszMsuQCZWZmWXKBMjOz\nLLlAmZlZllygzMwsSy5QZmaWJRcoMzPLkguUmZllyQXKzMyy5AJlZmZZcoEyM7MsuUCZmVmWXKDM\nzCxLtRYoSUdIWiNpraTTmsx/t6QbJV0n6QpJA3XGY9aJnEfWq2orUJL6gHOAI4H9gaWS9m9o9nNg\nKCL+FPg34Oy64jHrRM4j62V17kG9EFgbEesi4mHgIuCYcoOI+I+IeCCNXg0sqjEes07kPLKeVWeB\nWghsKo1vTtMm8hbgu81mSFomaVTS6NjYWAtDNMtey/IInEvWWeosUGoyLZo2lN4IDAH/1Gx+RJwb\nEUMRMdTf39/CEM2y17I8AueSdZbZNfa9GdirNL4IuLmxkaSXA/8DeGlEPFRjPGadyHlkPavOPahr\ngCWS9pY0FzgeWFFuIOl5wBeBoyPi9hpjMetUziPrWbUVqIjYApwMXA7cBFwcETdIOlPS0anZPwGP\nA74h6VpJKybozqwnOY+sl9V5iI+IuAy4rGHa6aXnL69z+WbdwHlkvcp3kjAzsyy5QJmZWZZcoMzM\nLEsuUGZmliUXKDMzy5ILlJmZZckFyszMsuQCZWZmWXKBMjOzLLlAmZlZllygzMwsSy5QZmaWJRco\nMzPLkguUmZllyQXKzMyy5AJlZmZZcoEyM7MsuUCZmVmWXKDMzCxLLlBmZpYlFygzM8uSC5SZmWXJ\nBcrMzLLkAmVmZllygTIzsyy5QJmZWZZcoMzMLEsuUGZmliUXKDMzy5ILlJmZZckFyszMslRrgZJ0\nhKQ1ktZKOq3J/F0kfT3N/6mkwR1ZzvLlyxkcHGTWrFkMDg6yfPnynW7b6nbtXnZV7VzvdsZZR4yt\nNFO5ZJaViKhlAPqAXwP7AHOBXwD7N7Q5CfhCen488PWp+j3wwAOjbGRkJObPnx/Ao8P8+fNjZGQk\nGlVt2+p27V52Ve1c73bGOZ0YgdGoKWcmGmYql7rWqlURH/lI8TiT7bpt2S3ss2oe1ZlUBwOXl8bf\nB7yvoc3lwMHp+WzgDkCT9duYVAMDA9u8sYwPAwMD2/1RqrZtdbt2L7uqdq53O+OcToxtKlAzkktd\nadWqiHnzIvr6iseJ3lhb3a7blt3iPqvmUZ2H+BYCm0rjm9O0pm0iYgtwD/Dkxo4kLZM0Kml0bGxs\nm3kbN25suvBm06u2bXW7di+7qnau93R0wt+yxWYkl7rSypXw8MOwdWvxuHLlzLTrtmXX1ecU6ixQ\najItdqANEXFuRAxFxFB/f/828xYvXtx04c2mV23b6nbtXnZV7Vzv6eiEv2WLzUgudaXhYZg7F/r6\nisfh4Zlp123LrqvPqVTZzdqRgRk6LNEp54F8DirfODvgHJQP8e2MbjoP5HNQLUuq2cA6YG8eO7H7\nrIY272TbE7sXT9Vvs6QaGRmJgYGBkBQDAwOTvvlVbdvqdu1edlXtXO92xlm1XZsK1IzlktlMqJpH\nKtrWQ9JRwKcorkI6LyLOknRmCm6FpF2BrwLPA+4Ejo+IdZP1OTQ0FKOjo7XFbDYZSasjYqgNy3Uu\nWdeomkez6wwiIi4DLmuYdnrp+YPAcXXGYNYNnEvWi3wnCTMzy5ILlJmZZckFyszMsuQCZWZmWar1\nKr46SBoDNrQ7jp20gOJ7Kt2gm9YFpl6fgYjoim+4dkEu9dq212kmW59KedRxBaobSBptx6XKdeim\ndYHuW59u1m3/K6/P9nyIz8zMsuQCZWZmWXKBao9z2x1AC3XTukD3rU8367b/ldengc9BmZlZlrwH\nZWZmWXKBMjOzLLlAzSBJ6yVdL+laSR13G2lJ50m6XdIvS9OeJOkHkv4zPe7RzhinY4L1OUPSb9P/\n6Np0F3HLjHMpL3XlkgvUzHtZRDy3Q7/vcD5wRMO004ArImIJcEUa7xTns/36AHwy/Y+em+4ibnly\nLuXjfGrIJRcoqywirqT4raGyY4AL0vMLgGNnNKidMMH6mNXOuVSNC9TMCuD7klZLWtbuYFrkqRFx\nC0B6fEqb42mFkyVdlw5bdMxhlh7jXOoMO5VLLlAz65CIeD5wJPBOSYe2OyDbzueBfYHnArcAH29v\nODYB51L+djqXXKBmUETcnB5vB/438ML2RtQSt0l6OkB6vL3N8eyUiLgtIrZGxCPAv9Id/6Ou41zK\nXytyyQVqhkjaTdLu48+Bw4FfTv6qjrACOCE9PwH49zbGstPG3yCSV9Md/6Ou4lzqDK3IJd9JYoZI\n2ofikx7AbOBrEXFWG0OaNkkXAsMUt9G/DfggcAlwMbAY2AgcFxEdceHBBOszTHFIIoD1wNvHzwtY\nHpxL+akrl1ygzMwsSz7EZ2ZmWXKBMjOzLLlAmZlZllygzMwsSy5QZmaWJReoGSZpa+nuvtdKqvWG\nkJKOnoFlDEt6cZPpu0n6QXr+Y0mz64zDeofzqDf0zIpm5A8R8dyZWJCk2RGxguILgHUaBu4DVjVM\nPxi4Ot2D6/6I2FJzHNY7nEc9wN+DmmGS7ouIxzVMewLwM+DoiFiTvvT2fyLiXyXdB3wReBlwF3B8\nRIxJ2hc4B+gHHgDeFhG/knQ+xV2Fnwf8X+B6YCgiTk7z/gA8ExgA3kzxjfWDgZ9GxIkpnsOBDwG7\nAL8G3hwR90laT3GX5VcBc4DjgAeBq4GtwBjwLuBm4JvA04D7AQHzgVuBw9Ptacx2mPOoR/IoIjzM\n4ECxAV5bGl6Xph8GXAUcD3yv1D6AN6TnpwOfTc+vAJak5wdRJCIUv8vybaAvjZ9Yes35wEUUG/ox\nwL3AcygO9a6m+Nb3AuBKYLf0mvcCp6fn64F3pecnAV9Kz88A/rbJun4HeHKa/8p2/+09dM/gPOqN\nwYf4Zl7TQxMR8QNJx1F8mjugNOsR4Ovp+QjwLUmPA14MfEPSeLtdSq/5RkRsnWD5l0ZESLoeuC0i\nrgeQdAMwCCwC9gd+kvqeS5Hw476VHlcDr5liXZ8SEb+T9ByKm0WatYrzqAe4QGVC0ixgP4pDB08C\nNk/QNCg+qd3dLEGT+ydZ1EPp8ZHS8/Hx2RSfTH8QEUuneP1WJth+JH0BeAmwSNK1wBLgO5IuiIhP\nThKb2U5xHnUXX8WXj1OBm4ClwHmS5qTps4C/TM9fD/w4Iu4FfpM+KaLCAY0d7qCrgUMk/Unqe76k\nZ0zxmt8Du4+PRMQ7KI69f5jiV0G/E8VPPvdEUllbOY+6iAvUzJvXcHnsx9KG+1bgPRHxI4pj1x9I\n7e8HniVpNfDnwJlp+huAt0j6BXADxbHwnRYRYxTH2y+UdB1Foj1zipddCrw6rc+fpWkvBX4E/Bnw\nw1bEZlbiPOoBvoovc82uVjKz6XEedSbvQZmZWZa8B2VmZlnyHpSZmWXJBcrMzLLkAmVmZllygTIz\nsyy5QJmZWZb+P+RhgVS0bj8FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a1ce89710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y_hat, 'ko')\n",
    "plt.title('Context prediction')\n",
    "plt.xlabel('Experiment#')\n",
    "plt.ylabel('Prediction')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.title('Actual context')\n",
    "plt.xlabel('Experiment#')\n",
    "plt.ylabel('Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_vs_actual.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
