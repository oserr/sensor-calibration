{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from os import path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datadir, expdir, expnum):\n",
    "    '''Creates data frames from a list of files.\n",
    "    \n",
    "    :param datadir\n",
    "        The data directory containing the expriment directories.\n",
    "    :param expdir\n",
    "        A list of expriment directories.\n",
    "    :param expnum\n",
    "        The number of expriment trials per experiment.\n",
    "    :return\n",
    "        A list of data frames.\n",
    "    '''\n",
    "    assert datadir, 'datadir must name a path'\n",
    "    assert expdir, 'expdir cannot be empty'\n",
    "    assert expnum > 0, 'expnum must be greater than zero'\n",
    "    dfs = []\n",
    "    for ed in expdir:\n",
    "        for n in range(1,expnum+1):\n",
    "            filename = '{}-{}.csv'.format(ed, n)\n",
    "            filepath = path.join(datadir, ed, filename)\n",
    "            df = pandas.read_csv(filepath)\n",
    "            dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'data/clean'\n",
    "experiment_dirs = ['exp1', 'exp2', 'exp3']\n",
    "experiment_trials = 5\n",
    "\n",
    "dfs = get_data(datadir, experiment_dirs, experiment_trials)\n",
    "df1 = dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rx', 'ry', 'rz', 'ax', 'ay', 'az', 'mx', 'my', 'mz', 'apprx', 'appry',\n",
      "       'apprz', 'appax', 'appay', 'appaz', 'appmx', 'appmy', 'appmz',\n",
      "       'incontext', 'nocontext'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# The number of columns that will be the input for the neural net model\n",
    "num_cols = len(df1.columns) - 2\n",
    "\n",
    "# Look at the column\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rx</th>\n",
       "      <th>ry</th>\n",
       "      <th>rz</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>mx</th>\n",
       "      <th>my</th>\n",
       "      <th>mz</th>\n",
       "      <th>apprx</th>\n",
       "      <th>appry</th>\n",
       "      <th>apprz</th>\n",
       "      <th>appax</th>\n",
       "      <th>appay</th>\n",
       "      <th>appaz</th>\n",
       "      <th>appmx</th>\n",
       "      <th>appmy</th>\n",
       "      <th>appmz</th>\n",
       "      <th>incontext</th>\n",
       "      <th>nocontext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114776</td>\n",
       "      <td>0.439484</td>\n",
       "      <td>-0.700906</td>\n",
       "      <td>-0.694898</td>\n",
       "      <td>1.077169</td>\n",
       "      <td>1.150464</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>1.636875</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>-1.858940</td>\n",
       "      <td>2.150135</td>\n",
       "      <td>-0.256785</td>\n",
       "      <td>-0.729854</td>\n",
       "      <td>0.786804</td>\n",
       "      <td>-0.229297</td>\n",
       "      <td>-1.041701</td>\n",
       "      <td>0.488485</td>\n",
       "      <td>0.869405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.178055</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>-0.702962</td>\n",
       "      <td>-1.150445</td>\n",
       "      <td>0.410662</td>\n",
       "      <td>0.727458</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>1.636875</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>-1.597529</td>\n",
       "      <td>2.224365</td>\n",
       "      <td>-0.488612</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>1.434085</td>\n",
       "      <td>-0.007593</td>\n",
       "      <td>-1.046289</td>\n",
       "      <td>0.472745</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058157</td>\n",
       "      <td>0.161305</td>\n",
       "      <td>-0.709129</td>\n",
       "      <td>-0.919738</td>\n",
       "      <td>0.436072</td>\n",
       "      <td>1.006316</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-1.446922</td>\n",
       "      <td>1.882911</td>\n",
       "      <td>-0.719377</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>1.362472</td>\n",
       "      <td>-0.043567</td>\n",
       "      <td>-1.019131</td>\n",
       "      <td>0.478037</td>\n",
       "      <td>0.818819</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.607691</td>\n",
       "      <td>-0.657604</td>\n",
       "      <td>-0.657735</td>\n",
       "      <td>-1.256180</td>\n",
       "      <td>1.065773</td>\n",
       "      <td>0.232592</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-1.059426</td>\n",
       "      <td>1.048598</td>\n",
       "      <td>-0.818543</td>\n",
       "      <td>1.110339</td>\n",
       "      <td>0.871966</td>\n",
       "      <td>-0.317667</td>\n",
       "      <td>-0.992060</td>\n",
       "      <td>0.462353</td>\n",
       "      <td>0.760988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.544411</td>\n",
       "      <td>-1.017048</td>\n",
       "      <td>-0.672639</td>\n",
       "      <td>-0.430083</td>\n",
       "      <td>0.144706</td>\n",
       "      <td>-0.634227</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.712917</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>-0.345418</td>\n",
       "      <td>0.132309</td>\n",
       "      <td>-0.549512</td>\n",
       "      <td>0.980732</td>\n",
       "      <td>0.227001</td>\n",
       "      <td>-0.785198</td>\n",
       "      <td>-1.010228</td>\n",
       "      <td>0.446591</td>\n",
       "      <td>0.739677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rx        ry        rz        ax        ay        az        mx  \\\n",
       "0 -0.114776  0.439484 -0.700906 -0.694898  1.077169  1.150464  0.073693   \n",
       "1 -0.178055  0.136300 -0.702962 -1.150445  0.410662  0.727458  0.073693   \n",
       "2 -0.058157  0.161305 -0.709129 -0.919738  0.436072  1.006316  0.001939   \n",
       "3 -0.607691 -0.657604 -0.657735 -1.256180  1.065773  0.232592  0.001939   \n",
       "4 -0.544411 -1.017048 -0.672639 -0.430083  0.144706 -0.634227  0.001939   \n",
       "\n",
       "         my        mz     apprx     appry     apprz     appax     appay  \\\n",
       "0  1.636875  0.559617 -1.858940  2.150135 -0.256785 -0.729854  0.786804   \n",
       "1  1.636875  0.559617 -1.597529  2.224365 -0.488612  0.005991  1.434085   \n",
       "2  1.712917  0.227799 -1.446922  1.882911 -0.719377  0.667759  1.362472   \n",
       "3  1.712917  0.227799 -1.059426  1.048598 -0.818543  1.110339  0.871966   \n",
       "4  1.712917  0.227799 -0.345418  0.132309 -0.549512  0.980732  0.227001   \n",
       "\n",
       "      appaz     appmx     appmy     appmz  incontext  nocontext  \n",
       "0 -0.229297 -1.041701  0.488485  0.869405          1          0  \n",
       "1 -0.007593 -1.046289  0.472745  0.862275          1          0  \n",
       "2 -0.043567 -1.019131  0.478037  0.818819          1          0  \n",
       "3 -0.317667 -0.992060  0.462353  0.760988          1          0  \n",
       "4 -0.785198 -1.010228  0.446591  0.739677          1          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a small sample of the data\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first row of the trial experiment 0\n",
      "[-0.114776  0.439484 -0.700906 -0.694898  1.077169  1.150464  0.073693\n",
      "  1.636875  0.559617 -1.85894   2.150135 -0.256785 -0.729854  0.786804\n",
      " -0.229297 -1.041701  0.488485  0.869405]\n",
      "The target for the trial experiment 0\n",
      "[ 1.  0.]\n",
      "\n",
      "The first row of the trial experiment 5\n",
      "[ 0.247633 -0.314106 -0.22799   0.399076  0.434287 -0.103136  0.182777\n",
      " -2.316515  4.607624  0.090366 -0.229647 -0.274152 -0.118235  0.070525\n",
      "  0.065246 -2.501649 -1.409344  0.614023]\n",
      "The target for the trial experiment 5\n",
      "[ 0.  1.]\n",
      "\n",
      "The first row of the trial experiment 10\n",
      "[ 0.06957  -0.053842 -0.671361 -0.884662 -0.087146  0.641166  0.518448\n",
      " -1.077423  2.031714 -0.244218  0.235017  0.184547 -0.378222  0.101676\n",
      " -0.034164  3.003549 -2.023913 -1.924938]\n",
      "The target for the trial experiment 10\n",
      "[ 0.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_to_input(dfs):\n",
    "    '''Converts a list of data frames to a pair of lists of inputs and targets.\n",
    "    \n",
    "    :param dfs\n",
    "        A list of data frames, where each data frame contains sensor readings from the PowerDue and PowerSense.\n",
    "    :return\n",
    "        A pair of lists (inputs, targets), where\n",
    "        - each input in inputs is an array of the sensor readings for one experiment.\n",
    "        - each target in targets is a vector of length two, where\n",
    "          - [1, 0] represents a target where the PowerDue and mobile phone share context.\n",
    "          - [0, 1] represents a target where the PowerDue and mobile phone do not share context.\n",
    "    '''\n",
    "    assert dfs, 'dfs cannot be empty'\n",
    "    values = []\n",
    "    targets = []\n",
    "    cols = dfs[0].columns\n",
    "    value_cols = cols[:-2]\n",
    "    target_cols = cols[-2:]\n",
    "    for df in dfs:\n",
    "        value = df[value_cols].values\n",
    "        target = df.iloc[0][target_cols].values\n",
    "        values.append(value)\n",
    "        targets.append(target)\n",
    "    return values, targets     \n",
    "\n",
    "inputs, targets = convert_to_input(dfs)\n",
    "for i in range(0, len(inputs), 5):\n",
    "    value, target = inputs[i], targets[i]\n",
    "    print('The first row of the trial experiment %d' % i)\n",
    "    print(value[0, :])\n",
    "    print('The target for the trial experiment %d' %i)\n",
    "    print(target)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays have 2431 rows\n"
     ]
    }
   ],
   "source": [
    "def normalize_rows(data):\n",
    "    '''Normalizes the rows in data by making them have the same number of rows.\n",
    "    \n",
    "    The number of rows that for each array will be the average number of rows.\n",
    "    If an array has less rows then needed, then the last row is repeated until\n",
    "    the array has the correct number of rows. If the array has more rows than\n",
    "    needed, then the last rows are dropped.\n",
    "    \n",
    "    :param data\n",
    "        A list of arrays\n",
    "    :return\n",
    "        A list of arrays with the same number of rows.\n",
    "    '''\n",
    "    assert len(data) != 0, 'cannot divide by zero'\n",
    "    rows_mean = int(sum(arr.shape[0] for arr in data) / len(data))\n",
    "    new_data = []\n",
    "    for arr in data:\n",
    "        rows = arr.shape[0]\n",
    "        if rows > rows_mean:\n",
    "            new_data.append(arr[:rows_mean, :])\n",
    "        elif rows < rows_mean:\n",
    "            diff_rows = rows_mean - rows\n",
    "            # Repeat the last row\n",
    "            arr_repeat = numpy.tile(arr[-1,:], (diff_rows, 1))\n",
    "            new_arr = numpy.append(arr, arr_repeat, axis=0)\n",
    "            new_data.append(new_arr)\n",
    "        else:\n",
    "            new_data.append(arr)\n",
    "    return new_data\n",
    "\n",
    "# Verify that all arrays have same number of rows\n",
    "norm_rows_data = normalize_rows(inputs)\n",
    "rows_num = norm_rows_data[0].shape[0]\n",
    "assert all(rows_num == arr.shape[0] for arr in norm_rows_data), \\\n",
    "    'not all arrays have the same number of rows'\n",
    "print('All arrays have {} rows'.format(rows_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xform_data.shape: (15, 2431, 18, 1)\n",
      "input_shape: (2431, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "def reshape_data(data):\n",
    "    '''Reshapes 2d arrays into 3d arrays.\n",
    "    \n",
    "    :param data\n",
    "        A list of 2d numpy arrays\n",
    "    :return\n",
    "        A list of 3d numpy arrays and a tuple of input parameters that can be fed to a Keras layer.\n",
    "    '''\n",
    "    new_data = numpy.array(data)\n",
    "    samples, rows, cols = new_data.shape\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        new_data = new_data.reshape(samples, 1, rows, cols)\n",
    "        input_shape = (1, rows, cols)\n",
    "    else:\n",
    "        new_data = new_data.reshape(samples, rows, cols, 1)\n",
    "        input_shape = (rows, cols, 1) \n",
    "    return input_shape, new_data\n",
    "\n",
    "input_shape, xform_data = reshape_data(norm_rows_data)\n",
    "print('xform_data.shape:', xform_data.shape)\n",
    "print('input_shape:', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    '''Creates an uncompiled neural net model.\n",
    "    \n",
    "    :return\n",
    "        An uncompiled neural net model.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_targets = numpy.array(targets)\n",
    "arr_inputs = xform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n",
      "score= [0.029746450483798981, 1.0]\n",
      "acc: 100.00%\n",
      "score= [1.1920930376163597e-07, 1.0]\n",
      "acc: 100.00%\n",
      "score= [16.118095397949219, 0.0]\n",
      "acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Compile the neural net\n",
    "nsamples = arr_inputs.shape[0]\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "zeros = numpy.zeros(nsamples)\n",
    "# Leave one out k-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=nsamples, shuffle=True, random_state=seed)\n",
    "scores = []\n",
    "for train, test in kfold.split(zeros, zeros):\n",
    "    model = create_model(input_shape)\n",
    "    # Compile model\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    train_inputs = arr_inputs[train]\n",
    "    train_targets = arr_targets[train]\n",
    "    model.fit(train_inputs, train_targets, epochs=20, batch_size=10, verbose=0)\n",
    "    test_input = arr_inputs[test]\n",
    "    test_target = arr_targets[test]\n",
    "    score_tuple = model.evaluate(test_input, test_target, verbose=0)\n",
    "    score = int(score_tuple[1])\n",
    "    print('score=', score_tuple, 'GUESSED RIGHT!!!' if score else 'WRONG!!!')\n",
    "    scores.append((test[0], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (7, 0), (8, 0), (9, 0), (10, 0), (11, 0), (12, 0), (13, 0), (14, 0)]\n",
      "Guessed 0/15 correct\n"
     ]
    }
   ],
   "source": [
    "# See which experiment trials are predicted correctly (i.e., second element is 1)\n",
    "scores.sort()\n",
    "print('Scores:', scores)\n",
    "correct = sum(guess for _, guess in scores)\n",
    "print('Guessed {}/{} correct'.format(correct, len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather results to plot predictions against actual data\n",
    "\n",
    "x = list(range(1,len(scores)+1))\n",
    "\n",
    "y_hat, y = [], []\n",
    "for i, s in scores:\n",
    "    if i < 5:\n",
    "        actual = 1\n",
    "        guess = 1 if s else 0\n",
    "    else:\n",
    "        guess = 0 if s else 1\n",
    "        actual = 0\n",
    "    y_hat.append(guess)\n",
    "    y.append(actual)\n",
    "    \n",
    "y = x\n",
    "y_hat = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f916387b278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y_hat, 'ko')\n",
    "plt.title('Context prediction')\n",
    "plt.xlabel('Experiment#')\n",
    "plt.ylabel('Prediction')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.title('Actual context')\n",
    "plt.xlabel('Experiment#')\n",
    "plt.ylabel('Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
