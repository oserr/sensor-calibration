{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bb8deb65d4c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from os import path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datadir, expdir, expnum):\n",
    "    '''Creates data frames from a list of files.\n",
    "    \n",
    "    :param datadir\n",
    "        The data directory containing the expriment directories.\n",
    "    :param expdir\n",
    "        A list of expriment directories.\n",
    "    :param expnum\n",
    "        The number of expriment trials per experiment.\n",
    "    :return\n",
    "        A list of data frames.\n",
    "    '''\n",
    "    assert datadir, 'datadir must name a path'\n",
    "    assert expdir, 'expdir cannot be empty'\n",
    "    assert expnum > 0, 'expnum must be greater than zero'\n",
    "    dfs = []\n",
    "    for ed in expdir:\n",
    "        for n in range(1,expnum+1):\n",
    "            filename = '{}-{}.csv'.format(expdir, n)\n",
    "            filepath = path.join(datadir, expdir, filename)\n",
    "            df = pandas.read_csv(filepath)\n",
    "            dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def convert_to_input(dfs):\n",
    "    '''Converts a list of data frames to a pair of lists of inputs and targets.\n",
    "    \n",
    "    :param dfs\n",
    "        A list of data frames, where each data frame contains sensor readings from the PowerDue and PowerSense.\n",
    "    :return\n",
    "        A pair of lists (inputs, targets), where\n",
    "        - each input in inputs is an array of the sensor readings for one experiment.\n",
    "        - each target in targets is a vector of length two, where\n",
    "          - [1, 0] represents a target where the PowerDue and mobile phone share context.\n",
    "          - [0, 1] represents a target where the PowerDue and mobile phone do not share context.\n",
    "    '''\n",
    "    assert dfs, 'dfs cannot be empty'\n",
    "    values = []\n",
    "    targets = []\n",
    "    cols = dfs[0].columns\n",
    "    value_cols = cols[:-2]\n",
    "    target_cols = cols[-2:]\n",
    "    for df in dfs:\n",
    "        value = df[value_cols].values\n",
    "        target = df[0, target_cols].values\n",
    "        values.append(value)\n",
    "        targets.append(target)\n",
    "    return values, targets     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'data/clean'\n",
    "experiment_dirs = ['exp1', 'exp2', 'exp3']\n",
    "experiment_trials = 5\n",
    "\n",
    "dfs = get_data(datadir, expriment_dirs, experiment_trials)\n",
    "df1 = dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of columns that will be the input for the neural net model\n",
    "num_cols = len(df1.columns) - 2\n",
    "\n",
    "# Look at the column\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a small sample of the data\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = convert_to_input(dfs)\n",
    "for i in range(0, len(inputs), 5):\n",
    "    value, target = inputs[i], targets[i]\n",
    "    print('The first row of the trial experiment %d' % i)\n",
    "    print(value[0, :])\n",
    "    print('The target for the trial experiment %d' %i)\n",
    "    print(target)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    '''Creates an uncompiled neural net model with a given architecture.\n",
    "    \n",
    "    :return\n",
    "        An uncompiled neural net model.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=2, kernel_size=2, padding='same', activation='relu', input_shape=(None, num_cols))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=4, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=8, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the neural net\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# Leave one out k-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=len(inputs), shuffle=True, random_state=seed)\n",
    "scores = []\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    model = create_model()\n",
    "    # Compile model\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    train_inputs = inputs[train]\n",
    "    train_targets = targets[train]\n",
    "    print('train_targets:', train_targets)\n",
    "    model.fit(train_inputs, train_targets, epochs=20, batch_size=10, verbose=0)\n",
    "    test_input = inputs[test]\n",
    "    test_target = targets[test]\n",
    "    print('test_target:', test_target)\n",
    "    score = model.evaluate(test_input, test_target, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "    score_data = (test, score[1]*100)\n",
    "    scores.append(score_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores:', scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
