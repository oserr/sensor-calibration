%\documentclass[onecolumn]{IEEEtranTIE}
\documentclass[journal]{IEEEtranTIE}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{picinpar}
\usepackage{amsmath}
\usepackage{url}
\usepackage{flushend}
\usepackage[latin1]{inputenc}
\usepackage{colortbl}
\usepackage{soul}
\usepackage{multirow}
\usepackage{pifont}
\usepackage{color}
\usepackage{alltt}
\usepackage[hidelinks]{hyperref}
\usepackage{enumerate}
\usepackage{siunitx}
\usepackage{listings}
\usepackage{breakurl}
\usepackage{epstopdf}
\usepackage{pbox}

\begin{document}
\title{	ConAuth - context for authentication \\ (Dec. 2017)}

\author{
	\vskip 1em
	{
	Saurabh Sharma, \emph{saurabh.sharma@sv.cmu.edu}\\
	Omar Serrano, \emph{omar.serrano@sv.cmu.edu}
	}
}

\maketitle

\begin{abstract}
With the growing number of wireless devices, we need efficient mechanisms to let
the wireless devices communicate securely. The wireless devices sometimes share
common sensors that can be leveraged to perform additional authentication
procedures on a set of localized wireless devices. The problem which prevents
such a judicious use of sensors is the orientation of wireless devices. Sensors
such as gyroscope and accelerometer are commonly found in wireless devices, but
their readings make no sense until their orientations are the same. We plan to
conduct controlled experiments to investigate how different environmental factors
impact the accelerometer performance and how the best accuracy can be achieved
in an appropriate condition range. We also characterize the nature of an
accelerometer to understand its performance in different conditions. Based on
such comprehensive understanding, we propose to estimate the phone attitude and
provide for opportunistic calibration of the accelerometer.
\end{abstract}

\begin{IEEEkeywords}
Contextual security, sensor funsion, Madgwick, device orientation.
\end{IEEEkeywords}

\definecolor{limegreen}{rgb}{0.2, 0.8, 0.2}
\definecolor{forestgreen}{rgb}{0.13, 0.55, 0.13}
\definecolor{greenhtml}{rgb}{0.0, 0.5, 0.0}

\section{Introduction}

\IEEEPARstart{W}{ith}
the growing number of IoT devices, securely pairing a new device into an
existing set of devices is an extremely important yet burdensome task.
Traditionally, these devices are paired manually, where an operator sets up an
authentication with the existing network of devices. Specifically, we address
the problem of a platoon ghost attack wherein an attacker device spoofs presence
within a platoon to gain admission and subsequently execute malicious attacks
\cite{Han}. To address such concerns, we explore the notion of fingerprinting
device sensor readings for a device's context.

Devices that share context are expected to experience similar events. For
example, two magnetometers in proximity are likely to processes similar events
if a magnetic strip is drawn close to them. Even if the readings are not exactly
the same, the devices are likely to exhibit similar patterns as a result of the
magnetic disturbance caused by the magnetic strip. Two video cameras, despite
having different points of view, might be able to determine that they share
context on the basis that both of them detect an object with similar shape and
color; for example, if one of the video cameras records an invidual with a blue
shirt walking toward it, and the other camera records an invidual with a blue
shirt walking away from it.

There is a wide range of possibilities in how devices and sensors are used to
determine context from a wide variety of physical stimuli, or how the scale of
context is defined (e.g., school building vs a single room); however, we limit
our research to the small context of a car, and to 3-dimensional orientation,
acceleration, and magnetic sensor readings. Instead of relying on traditional
methods (e.g, Kalam filter) to determine context from the type of sensors we are
using, we employ a convolutional neural network, a popular technique for solving
computer vison problems, to create a predictive model.

\section{Problem Statement}

With near-ubiquitous availability of wireless devices equipped with a wide
variety of sensors, research in building context aware services has been
growing. However, despite a large number of services proposed and developed as
research prototypes, the number of truly context-aware applications available in
wireless devices is quite limited. A major barrier for the large-scale
proliferation of context aware applications is poor accuracy \cite{Alanezi}.
We address one of the key reasons for this poor accuracy, which is the impact of
sensor orientation.

Devices have their sensors oriented in different positions. We first show that
smartphone positions significantly affect the values of the
sensor data being collected by a context aware application, and this in turn
has a significant impact on the accuracy of the application \cite{Alanezi}.
Next, it describes the design and prototype development of a orientation
discovery service that accurately detects a sensor orientation. This service is
based on the sensor data collected from carefully chosen sensors. Finally, the
paper demonstrates that the accuracy of an existing context aware service or
application is significantly enhanced when run in conjunction with the proposed
orienttion discovery service.

\section{Related Work}

To complete the work for this paper, we relied on multiple open source libraries
to collect data, and to build a neural network architecture to generate a model
for predicting the context of a device. We were able to use the MPU9250 SparkFun
library \cite{MPU9250}, with minor modifications, to collect three-dimensional
orientation, acceleration, and magnetic sensor readings from the PowerDue. To be
able to compare the data from the PowerDue and the mobile phone, readings from
both devices had to be time-stamped, and the RTCDue \cite{RTCDue} and Time
\cite{TimeLib} Arduino libraries allowed us to generate timestamps with the
PowerDue. Implementing neural network architectures is not a trivial task, but
Keras \cite{Keras}, a python deep learning library which uses TensorFlow as a
backend, made it easy for us to create a neural net that we could then train and
use to make predictions. While Keras made it easy to implement a neural network,
\cite{LeCunn,DeepLearning} inspired us to try a deep learning solution, and
\cite{DeepLearning,Dropout} were helpful in understanding the intricacies of
using neural networks effectively.


\begin{figure}[!t]\centering
	\includegraphics[width=8.5cm]{phoneOrientation}
	\caption{A device's body orientation.}\label{fig:fig1}
\end{figure}


\section{Approach}

To build a model to determine whether two devices share the same context, we
took the following approach:

\begin{enumerate}
\item Modify the MPU9250 library to work with the PowerDue.
\item Establish a clock on the PowerDue, to allow us to synchronize readings
      from the MPU9250 with readings from PowerSense.
\item Run three experiments to collect data from the MPU9250 and PowerSense iOS
      app. See Figure~\ref{fig:fig2} and Figure~\ref{fig:fig3} for an example of
      the type of data collected with PowerSense.
\item Use the unix timestamps to aggregate MPU9250 and PowerSense data.
\item Normalize the data.
\item Build a neural network architecture.
\item Train the neural network.
\item Evaluate the model.
\end{enumerate}

\begin{figure}[!t]\centering
	\includegraphics[width=5.5cm]{acceleration}
	\caption{User acceleration with iOS app PowerSense.}\label{fig:fig2}
\end{figure}

\begin{figure}[!t]\centering
	\includegraphics[width=5.5cm]{magnetic_field}
	\caption{Magnetic field with iOS app PowerSense.}\label{fig:fig3}
\end{figure}

\subsection{Modifying MPU9250 library}

The MPU9250 library, which implements an interface to interact with the MPU9250
sensor, which contains a 3D gyroscope, accelerometer, and magnetometer, required
only one modification to work with the PowerDue, updating the instances of the
\texttt{Wire} interface with \texttt{Wire1}, given that PowerDue has two wire
interfaces. In addition to this modification, we used a library example module
\cite{MPU9250Ex} as the basis for the PowerDue module that we used to obtain
readings from the MPU9250 sensor. We disabled most of the logic in the example
module, but nonetheless relied on critical sections of the module, such as
initializing and calibrating the sensor.

\subsection{Time Synchronization}

In order to be able to compare the readings from both devices, each reading had
to be timestamped, and the timestamps from the devices had to be relatable,
i.e., one timestamp could be converted to the other. PowerSense readings
provided a unix timestamp by default, and this was ideal, but the PowerDue did
not not have a system clock established, i.e., calling a clock time function
would begin counting time from zero.

To establish the system clock on the PowerDue, we used RTCDue, a library that
allows you to set the time in different ways \cite{RTCDue}, e.g., using a
unixtime stamp or a date. Ideally, we would have prefered to use the NTP
protocol to set the time on the PowerDue, because the time would have a greater
degree of accuracy. Unfortunately, we were unable to use NTP because we were
unable to get the Wi-Fi module to work. We tried approaches in different example
modules found within the PowerDue libraries, but none of them worked. Therefore,
we resorted to a compile-time mechanism for setting the time.

To set the time at compile-time, we passed in the macros \texttt{\_\_TIME\_\_}
and \texttt{\_\_DATE\_\_} to couple of RTCDue library functions to set the time
and date. Essentially, we would used the compiler to pass in the time when it
built the binary. Simply setting the time like this did not yield a very
accurate time, because of the delay between macro substitution at compile-time
and program execution. To offset this delay, we reset the time at runtime by
adding seconds to the time set with \texttt{\_\_TIME\_\_} and
\texttt{\_\_DATE\_\_}, essentially using inspection to pick the number of
seconds that made the time reported by PowerDue closer to the time reported by
our machines and PowerSense.

After setting the system clock, it was simply a matter of using the Time library
function \texttt{now} \cite{TimeLib} to output the unix timestamp with the
readings from the MPU9250. Ideally, we would have preferred a millisecond
accuracy level, which we might have obtained using NTP, but the compile-time
method of setting the time provided accuracy of within a second, allowing us to
carry on with the experiments.

\subsection{Experiments}

We conducted three sets of experiments from which we collected data. We defined
shared context to mean that both devices, the PowerDue and the mobile phone,
were inside of the same car. The experiments were:

\begin{itemize}
\item \textit{Shared context}. Drive vehicle with both devices inside of
      vechicle.
\item \textit{No shared context}. Drive vehicle with PowerDue inside vehicle,
      while mobile phone is carried by pedestrian.
\item \textit{No shared context}. Drive vehicle with PowerDue inside vehicle,
      and drive another vehicle with mobile phone inside it.
\end{itemize}

An essential ingredient of all the experiments was movement, in order to provide
stimulus for the sensors, and hence our decision to carry the experiments while
driving or walking. We repeated each experiment five times, and for each
experiment trial collected about a minute's worth of readings from each device.

The output of each experiment was a set of data files. PowerSense allowed us to
email the readings of an experiment as a CSV file to ourselves. For PowerDue, we
had to manually create a CSV file by copying the output from the serial console
to the file.

\subsection{Aggregating data}

There are a number of reasons why we aggregated the data from two data files to
one data file per experiment. One is convenience (e.g., uploading one data file
as a data frame vs multiple data files), but more importantly, to match the
readings from each device, which we did in a three step process.

\begin{enumerate}
\item Find the timestamps (i.e., seconds) where both devices output readings.
\item From each device's data file, select the readings with a timestamp from
      step 1.
\item In cases where the number of readings for a given second don't match,
      apply a transformation to make the number of readings for that second
      equal for both devices.
\end{enumerate}

Even though we tried to start and stop reading from each device at the same
time, it is inevitable to have slight variation when taking samples from more
devices, especially if there is a human element to the experiment, which there
was in our expriments because we started the readings manually by flashing the
program on the PowerDue and pressing a button the on the PowerSense app.
Therefore, we used only readings with timestamps in existing in both data files,
per step 2.

In step 3, we had to apply some transformations because PowerSense produced 50
readings per second, while PowerDue only produced 38 readings per second. To
smooth-out this difference, we mapped pairs of readings from PowerSense into a
single reading with the average of both readings, but we applied this only to
the tail end of the readings from PowerSense. For example, suppose $PD_s$ is the
set of readings $a_1, a_2, ..., a_{38}$ from the PowerDue, and $PS_s$ is the set
of readings $b_1, b_2, ..., b_{50}$ from PowerSense, for second $s$, and $a_i$
and $b_i$ represent vectors. Then the transformation applied to $PS_s$ would map
the last 24 readings to 12 readings, as indicated below:

\begin{align}
    b'_{26} &= \frac{b_{26} + b_{27}}{2} \\
    b'_{27} &= \frac{b_{28} + b_{29}}{2} \\
    \vdots \\
    b'_{38} &= \frac{b_{49} + b_{50}}{2}
\end{align}

\subsection{Data normalization}

After aggregating data by time, we normalized the data in two ways:

\begin{itemize}
\item Normalized all the data values (i.e., x, y, z and values for orientation,
      acceleration, and magnetic), so that the mean would be zero and the
      standard deviation 1.
\item Made all input arrays, obtained from each aggregate experiment file, have
      the same dimensions.
\end{itemize}

We normalized all the data values because having training data with a mean of
zero tends to seep up convergence \cite{DLTricks}. We also normalized every
input array to have the same number of rows, in order to be able to use a neural
network architecture with an convolutional layer and a dense output layer. To
make all the arrays have the same number of rows, we computed the average number
of rows per array (15 total arrays, one per experiment trial), and removed rows
from the end of arrays with more rows, or repeated the last row at the end of
arrays with less rows.

\subsection{Neural network architecture}

Our neural network architecture consists of 5 layers:

\begin{enumerate}
\item Input convolutional layer with a relu activation function.
\item Hidden convolutional layer with a relu activation function.
\item Hidden max pooling layer.
\item Hidden dense layer with a relu activation function.
\item Output dense layer with softmax activation function.
\end{enumerate}

With Keras \cite{Keras}, it was trivial to implement the network, as the
following lines of python code demonstrate

\begin{lstlisting}
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3),
                 activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))
\end{lstlisting}

Even though the data we collected is inherently time dependent, the way our
experiments were carried makes time less of an important variable, because we
did not carry out any experiments in which we tested changing context, i.e.,
going from sharing context to not sharing context. Such an experiment would have
required us to look at how the variables change over time, precisely so that we
could devise a model that can distinguish the moment when a device's state
changes from being in context to not being in context.

In our experiments, the devices are either in context, or not in context, there
is no change from one to the other. This motivated our decision to use a
convolutional neural network, where time is not a factor. We simply wanted to
classify the input as either in context, or not in context, hence an output
layer using a softmax function \cite{DeepLearning,LeCunn}.

From the code, it may seem like the network also has a \texttt{Dropout} layer;
however, dropout is not inherently part of the network, but rather a technique
used to randomly drop units of the network during training in order to prevent
overfitting of the model \cite{Dropout}.

\subsection{Training the network}

Given the small amount of data at our disposal, we used k-fold cross-validation
with $k=15$, or leave-one-out cross-validation \cite{StatLearn}. To use this
approach, we created and trained a model with 15 different sets of training
data, each time evaluating the model on a single instance, the one left out, of
the data.

\subsection{Evaluating results}

Overall, the model's prediction rate is somewhat surprising, because it predicts
8 out of 15 instances correctly, despite the small amount of data used to train
the models. However, on closer inspection, the results do not inspire a lot of
confidence on the model's prediction effectiveness, given that it predicts
almost all of the samples, except two, as not sharing context, and in both cases
where it predicts that the devices are sharing context it does so incorrectly.

Figure~\ref{fig:model_eval} illustrates the prediction results. The graph on the
left contains the predicted values, the graph on the right contains the actual
values, 1 and 0 represent context shared or not shared in the vertical axis, and
the horizontal axis represents the experiment trial. Thus, we can see that the
models predicts that data for trials one through five, where the context is
shared, as context not being shared. Therefore, and it may be a side effect of
the fact that we have more samples of data where the devices are not sharing
context, that the model is biased toward making predictions for context not
shared.

\begin{figure}[!t]\centering
	\includegraphics[width=5.5cm]{prediction_vs_actual}
	\caption{Model predictions vs actual data for devices sharing or not sharing
             context.}\label{fig:model_eval}
\end{figure}

\section{Conclusion}

There are many flaws in the work conducted for this experiment, including time
synchronization issues, the lack of a system for automating the process of
collecting experimental data, having only a small amount of data to train our
models, creating a model that does not take into account the fact that the state
of context being shared is dynamic.

Time is a key ingredient of whether two devices share context or not, and hence
time should be synchronized down to the level of milliseconds. Using a NTP would
have been a have made our results more accurate, but it would be even better to
develop a communication procotol that allows two devices to quickly reach
consesus on a measure of synchronizity, whether by time, a nonce, or some kind
of counter. Such a protocol does not need to be tied to hardware or sensors, and
hence could be applied any time devices are trying to synchronize with each
other.

We only collected 15 samples of data because it was very time consuming to
collect them - it took us about 3 hours to collect 15 samples. In addition to
being time consuming, it was error prone, given that most of it was done
manually. In one case, we forgot to copy and paste the output from one of the
experiments before proceeding to run the next experiment. Automating this
process, for example, by having PowerDue collect samples for some time before
sending them to the cloud, or an edge server, would allow us to collect more
data in a more effective and accurate manner.

Devices that are bound to a location have a static shared context with other
devices that are also bound near by; however, this is not a very interesting
instance of devices sharing context, because such devices can be programmed to
recognize that they share context. What's interesting about context being shared
between devices, or not, is that it is more likely to be dynamic, with devices
moving within and out of a state of shared context. Even devices that are bound
to a location will experien a change of state, because other mobile devices may
enter or leave their vicinity. Therefore, it would be more interesting and
realistic to develop a model that takes this dynamic into account, and hence it
would be more appropriate to use a different kind of neural network, such as an
LSTM network, or to simply use a different technique that is more appropriate
for time series and modelling state. To test such a model, it would be necessary
to devise experiments where devices share from one state to the other.

% References

\bibliographystyle{Bibliography/IEEEtranTIE}
\bibliography{Bibliography/IEEEabrv,Bibliography/BIB_1x-TIE-2xxx}\ %IEEEabrv instead of IEEEfull

\end{document}
